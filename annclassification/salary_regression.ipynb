{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据不包含缺失值。\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,945\n",
      "Trainable params: 2,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13393247232.0000 - mae: 100425.3828 - val_loss: 13043923968.0000 - val_mae: 98705.1406\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13381288960.0000 - mae: 100366.9453 - val_loss: 13023962112.0000 - val_mae: 98604.8203\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13351238656.0000 - mae: 100219.8438 - val_loss: 12988229632.0000 - val_mae: 98427.3125\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13306032128.0000 - mae: 99992.1953 - val_loss: 12938933248.0000 - val_mae: 98176.6250\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13247851520.0000 - mae: 99684.7891 - val_loss: 12884071424.0000 - val_mae: 97880.9141\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13187159040.0000 - mae: 99347.3750 - val_loss: 12836769792.0000 - val_mae: 97593.4844\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13142595584.0000 - mae: 99034.4844 - val_loss: 12807106560.0000 - val_mae: 97375.9453\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13114264576.0000 - mae: 98792.8750 - val_loss: 12786258944.0000 - val_mae: 97224.0469\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13088302080.0000 - mae: 98642.0547 - val_loss: 12764523520.0000 - val_mae: 97100.9219\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13060077568.0000 - mae: 98506.1094 - val_loss: 12730995712.0000 - val_mae: 96965.1016\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 13024537600.0000 - mae: 98373.9688 - val_loss: 12690352128.0000 - val_mae: 96802.1875\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12982035456.0000 - mae: 98222.4297 - val_loss: 12641838080.0000 - val_mae: 96605.7734\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12937678848.0000 - mae: 98050.3984 - val_loss: 12595096576.0000 - val_mae: 96395.1953\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12888821760.0000 - mae: 97849.1250 - val_loss: 12545959936.0000 - val_mae: 96164.8750\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12842484736.0000 - mae: 97635.3438 - val_loss: 12495388672.0000 - val_mae: 95928.0781\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12792503296.0000 - mae: 97407.8125 - val_loss: 12446347264.0000 - val_mae: 95684.7344\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12738864128.0000 - mae: 97143.9062 - val_loss: 12394567680.0000 - val_mae: 95428.5469\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12688527360.0000 - mae: 96902.9297 - val_loss: 12341450752.0000 - val_mae: 95165.9531\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12632768512.0000 - mae: 96628.4844 - val_loss: 12286092288.0000 - val_mae: 94891.5078\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12576378880.0000 - mae: 96351.3359 - val_loss: 12229771264.0000 - val_mae: 94609.3672\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12517953536.0000 - mae: 96073.1797 - val_loss: 12172435456.0000 - val_mae: 94321.0625\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12458629120.0000 - mae: 95774.0703 - val_loss: 12112514048.0000 - val_mae: 94019.9766\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12396164096.0000 - mae: 95461.5469 - val_loss: 12049147904.0000 - val_mae: 93701.0938\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12335689728.0000 - mae: 95170.4453 - val_loss: 11988471808.0000 - val_mae: 93397.0859\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12269204480.0000 - mae: 94830.5625 - val_loss: 11918338048.0000 - val_mae: 93041.5469\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12200938496.0000 - mae: 94509.1484 - val_loss: 11857469440.0000 - val_mae: 92739.4688\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12135286784.0000 - mae: 94170.0781 - val_loss: 11787530240.0000 - val_mae: 92381.7578\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 12063269888.0000 - mae: 93829.2500 - val_loss: 11740917760.0000 - val_mae: 92144.0000\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11997462528.0000 - mae: 93480.5703 - val_loss: 11653399552.0000 - val_mae: 91708.9844\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11928056832.0000 - mae: 93142.4297 - val_loss: 11587715072.0000 - val_mae: 91379.1719\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11856920576.0000 - mae: 92786.1172 - val_loss: 11520055296.0000 - val_mae: 91038.3359\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11782232064.0000 - mae: 92426.0781 - val_loss: 11449754624.0000 - val_mae: 90684.0859\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11708990464.0000 - mae: 92066.8906 - val_loss: 11365835776.0000 - val_mae: 90240.8438\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11636744192.0000 - mae: 91699.7188 - val_loss: 11293130752.0000 - val_mae: 89879.8203\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11554027520.0000 - mae: 91265.3984 - val_loss: 11208546304.0000 - val_mae: 89434.4688\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11464901632.0000 - mae: 90842.2031 - val_loss: 11125549056.0000 - val_mae: 89038.0000\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11382102016.0000 - mae: 90431.6719 - val_loss: 11049954304.0000 - val_mae: 88658.1016\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11302881280.0000 - mae: 90039.7656 - val_loss: 10966534144.0000 - val_mae: 88224.6484\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11219966976.0000 - mae: 89622.8906 - val_loss: 10880346112.0000 - val_mae: 87754.8203\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11141293056.0000 - mae: 89227.7266 - val_loss: 10799494144.0000 - val_mae: 87357.4375\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 11056429056.0000 - mae: 88789.8828 - val_loss: 10718157824.0000 - val_mae: 86948.7891\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10973591552.0000 - mae: 88371.7188 - val_loss: 10632054784.0000 - val_mae: 86499.9375\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10887459840.0000 - mae: 87979.8125 - val_loss: 10558281728.0000 - val_mae: 86149.4609\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10796093440.0000 - mae: 87494.5391 - val_loss: 10467380224.0000 - val_mae: 85654.6641\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10716410880.0000 - mae: 87112.6484 - val_loss: 10382354432.0000 - val_mae: 85243.6094\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10631058432.0000 - mae: 86687.7109 - val_loss: 10313463808.0000 - val_mae: 84916.8203\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10537331712.0000 - mae: 86233.8906 - val_loss: 10216451072.0000 - val_mae: 84412.7969\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10450015232.0000 - mae: 85781.5938 - val_loss: 10121112576.0000 - val_mae: 83912.3906\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10362220544.0000 - mae: 85348.2500 - val_loss: 10033510400.0000 - val_mae: 83474.4219\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 10276444160.0000 - mae: 84924.7109 - val_loss: 9944116224.0000 - val_mae: 83020.0156\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 9944116224.0000 - mae: 83020.0156\n",
      "Test loss: 9944116224.0\n",
      "Test MAE: 83020.015625\n",
      "To view the tensorboard, run the following command in the terminal:\n",
      "tensorboard --logdir regressionlogs/fit\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 59514), started 0:09:32 ago. (Use '!kill 59514' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c4ff0e18d71d6593\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c4ff0e18d71d6593\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "# Estimated Salary will be the output feature\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Check for missing values\n",
    "if data.isnull().any().any():\n",
    "    print(\"数据包含缺失值，请处理缺失值。\") \n",
    "    data = data.dropna()\n",
    "else:\n",
    "    print(\"数据不包含缺失值。\")\n",
    "    \n",
    "## Encode categorical data\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "onehot_encoder_geo = OneHotEncoder()\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography'])) \n",
    "\n",
    "# combine one-hot encoded columns with the original data\n",
    "data = pd.concat([data, geo_encoded_df], axis=1)\n",
    "data = data.drop(columns=['Geography'], axis=1)\n",
    "data.head()\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['EstimatedSalary'], axis=1) # Features\n",
    "y = data['EstimatedSalary'] # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale these features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.feature_names_in_ = X.columns\n",
    "\n",
    "# Save the encoded data and scaler for late use\n",
    "with open('label_encoder_gender.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder_gender, f)\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as f:\n",
    "    pickle.dump(onehot_encoder_geo, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "    \n",
    "# ANN Regression problem statement\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1)) # Output layer for regression\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime\n",
    "\n",
    "# Setup tensorboard\n",
    "log_dir = \"regressionlogs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, early_stopping])\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test MAE: {test_mae}')\n",
    "\n",
    "# save the model\n",
    "model.save('regression_model.h5')\n",
    "\n",
    "# Launch tensorboard\n",
    "print(\"To view the tensorboard, run the following command in the terminal:\")\n",
    "print(\"tensorboard --logdir regressionlogs/fit\")\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch tensorboard session\n",
    "%tensorboard --logdir regressionlogs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
